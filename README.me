"Customer Churn Prediction using Machine Learning"

Project Overview
    This project builds an end-to-end machine learning pipeline to predict customer churn using the Telco Customer Churn dataset. The objective is to identify customers likely to leave a service based on their demographic, service usage, and billing information.

    The project covers data cleaning, exploratory data analysis (EDA), feature engineering, model training, evaluation, and model persistence.

Business Problem
    Customer churn directly impacts company revenue. Predicting churn helps businesses proactively identify high-risk customers and design retention strategies such as targeted offers or service improvements.

Dataset
    Dataset: Telco Customer Churn Dataset
    Source: Kaggle
    Records: ~7000 customers
    Target Variable: Churn (Yes / No)

Tools & Technologies
    Python
    Pandas
    NumPy
    Matplotlib
    Seaborn
    Scikit-learn
    Joblib

Project Structure
    customer-churn-project/
    │
    ├── data/
    │   ├── raw/
    │   └── processed/
    │
    ├── notebooks/
    │   ├── 01_data_loading.ipynb
    │   ├── 02_data_cleaning.ipynb
    │   ├── 03_eda.ipynb
    │   └── 04_churn_modeling.ipynb
    │
    ├── models/
    │   ├── churn_model.pkl
    │   ├── churn_scaler.pkl
    │   └── random_forest_churn_model.pkl
    │
    ├── README.md
    └── requirements.txt

Data Cleaning & Preprocessing
    -Converted TotalCharges to numeric format
    -Removed missing values caused by blank billing entries
    -Removed customerID column
    -Converted Churn into binary numeric format
    -Performed one-hot encoding for categorical variables

Exploratory Data Analysis
    -Key insights discovered:
    -Customers with low tenure have higher churn risk
    -Month-to-month contracts show highest churn rate
    -Higher monthly charges slightly increase churn probability
    -Electronic check payment users show higher churn tendency

Machine Learning Models
    -Logistic Regression (Baseline Model)
    -Used as interpretable baseline classifier
    -Applied feature scaling using StandardScaler
    -Evaluated using Precision, Recall, F1-score, and ROC-AUC

Random Forest Classifier
    -Captures non-linear relationships and feature interactions
    -Provided feature importance insights
    -Used for model performance comparison

Model Evaluation
    -Models were evaluated using:
        --Classification Report
        --Confusion Matrix
        --ROC Curve
        --ROC-AUC Score

    -Logistic Regression and Random Forest showed comparable performance, with Random Forest providing better feature interpretability.

Feature Importance Insights
    -Top churn drivers identified:
        --TotalCharges
        --Tenure
        --MonthlyCharges
        --Fiber Internet Service
        --Electronic Check Payment Method

    -These features align with real-world customer retention patterns.

Model Persistence
    -Trained models and scaler were saved using Joblib for future predictions and deployment.

    -Saved Files:
        --Logistic Regression Model
        --Random Forest Model
        --Feature Scaler

Key Learnings
    -Handling imbalanced classification problems
    -Importance of correct evaluation metrics beyond accuracy
    -Feature importance interpretation for business insights
    -Model comparison and selection
    -End-to-end machine learning workflow

Author
    Pratham
    B.Tech – Computer Science Engineering